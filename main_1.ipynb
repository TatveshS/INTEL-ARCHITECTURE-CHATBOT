{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from urllib.request import urlretrieve\n",
    "import numpy as np\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "loader = PyPDFDirectoryLoader(\"./docs/\")\n",
    "\n",
    "\n",
    "#we are going to split documents to chunks of roughly 700 characters with an overlap of 50 characters.\n",
    "docs_before_split = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 700,\n",
    "    chunk_overlap  = 50,\n",
    ")\n",
    "docs_after_split = text_splitter.split_documents(docs_before_split)\n",
    "\n",
    "print(docs_after_split[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before split, there were 5620 documents loaded, with average characters equal to 2429.\n",
      "After split, there were 23865 documents (chunks), with average characters equal to 580 (average chunk length).\n"
     ]
    }
   ],
   "source": [
    "avg_doc_length = lambda docs: sum([len(doc.page_content) for doc in docs])//len(docs)\n",
    "avg_char_before_split = avg_doc_length(docs_before_split)\n",
    "avg_char_after_split = avg_doc_length(docs_after_split)\n",
    "\n",
    "print(f'Before split, there were {len(docs_before_split)} documents loaded, with average characters equal to {avg_char_before_split}.')\n",
    "print(f'After split, there were {len(docs_after_split)} documents (chunks), with average characters equal to {avg_char_after_split} (average chunk length).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
  
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample embedding of a document chunk:  [-0.07436386 -0.01998872 -0.00487509 -0.04411514 -0.00495798  0.01608374\n",
      " -0.02976514 -0.0292733   0.0136712  -0.02410323 -0.00374751  0.04361073\n",
      "  0.04644122 -0.05092742 -0.01117372 -0.03702448  0.0080249  -0.02212526\n",
      "  0.03765038  0.01640296  0.05425163 -0.01962815 -0.00200765 -0.02028733\n",
      " -0.02688534  0.03403157 -0.02158841 -0.04208039 -0.01581992 -0.17553467\n",
      " -0.00700382  0.02311602  0.1219614  -0.0125589  -0.01177902 -0.01615924\n",
      " -0.03740779  0.04749591 -0.05492797 -0.03859182  0.00445785  0.02535718\n",
      "  0.05207978 -0.02799923  0.03141743 -0.00261718 -0.02025448 -0.02933352\n",
      "  0.07278661 -0.02766144 -0.03099785  0.03073107  0.00741677  0.03022622\n",
      " -0.00773252  0.03148766  0.00364994  0.06883534  0.03887975 -0.03845931\n",
      "  0.01809014 -0.04526175 -0.14382744  0.13326585  0.02325645  0.07026108\n",
      " -0.02684466 -0.06027509  0.01477881 -0.00771915 -0.03375783  0.01078334\n",
      " -0.02800822 -0.02175796 -0.03199112 -0.04069415  0.03008674 -0.01559065\n",
      "  0.05108069 -0.07480058 -0.04482019  0.01754034 -0.00336831 -0.02352691\n",
      "  0.02644101  0.03892839  0.02204612  0.07897293  0.05138374 -0.04391805\n",
      " -0.04475761 -0.04486391 -0.00791394  0.04882003 -0.00498636  0.00071747\n",
      "  0.03111144 -0.02118046 -0.04118996  0.32681605  0.05061681 -0.08415713\n",
      " -0.06796995  0.02691674 -0.00637501  0.01001162  0.02838593 -0.02328918\n",
      " -0.0731852   0.0102051  -0.00857102  0.00336754  0.05483769 -0.01266882\n",
      "  0.0820391  -0.03776862  0.00169587 -0.01795038  0.06571035  0.00695522\n",
      " -0.00582848 -0.02719764  0.01409292 -0.03069763 -0.00827    -0.07660004\n",
      " -0.01680671  0.03331567  0.0150623   0.04532537  0.03527235  0.07253168\n",
      " -0.0391647  -0.01764216  0.06945299  0.06425652  0.0070768  -0.02380879\n",
      " -0.0651411  -0.04535769 -0.02902837  0.0156489   0.0192158  -0.03272833\n",
      " -0.00120202  0.16082291 -0.02365372  0.0263395   0.01218359  0.00780357\n",
      "  0.02163506  0.03360653  0.01129276 -0.02166974  0.01028571  0.04270073\n",
      "  0.0402634   0.05421677 -0.04307524 -0.04777941  0.00384523 -0.05700072\n",
      " -0.04122951  0.11398638  0.00934228 -0.09312731 -0.04984343  0.01677117\n",
      "  0.02196283 -0.02040825  0.00123545 -0.01463267 -0.02271797  0.0271998\n",
      "  0.06543041 -0.01983959  0.04594833  0.01806459  0.02046185  0.01285206\n",
      " -0.02434991 -0.03429919  0.04307289  0.05151051  0.0259035  -0.00608477\n",
      " -0.03814744 -0.05244403 -0.00035909  0.03297112 -0.0619588   0.0791592\n",
      " -0.0771997   0.08475403 -0.007512   -0.01237088 -0.02447917  0.03673523\n",
      " -0.0169116  -0.02617407  0.01633684  0.04046284 -0.03641485  0.01937015\n",
      " -0.05857179  0.01742435 -0.04946551 -0.03228041  0.02650577  0.01716821\n",
      " -0.04796927 -0.03510592 -0.00788737  0.00709122  0.00830776  0.0197194\n",
      "  0.02980821 -0.00572706 -0.02206488  0.00280969  0.00275776 -0.01112606\n",
      " -0.00116793 -0.29960588  0.05652446 -0.06779625 -0.07989705  0.00353975\n",
      " -0.05575502  0.0851329   0.00043184 -0.04611351  0.04928444  0.091225\n",
      " -0.05091083  0.02373993 -0.02526415 -0.00469423  0.0869619   0.01572554\n",
      " -0.04817395 -0.08084532 -0.01584835  0.01147454 -0.00181351 -0.06021801\n",
      " -0.03347576  0.01980266  0.05264497  0.0716963  -0.06999844  0.08438589\n",
      "  0.00484892  0.00455654  0.06149736  0.04824692 -0.02006279  0.01252636\n",
      "  0.05866364 -0.00582796  0.02715489  0.05884006 -0.04086709 -0.0545558\n",
      "  0.07520273  0.00707033 -0.02017233 -0.0128569  -0.07996874 -0.00203841\n",
      " -0.03217237 -0.0152466   0.02129049 -0.06517278  0.00344811 -0.02961817\n",
      "  0.06254341  0.00426897 -0.02186259 -0.04348272 -0.03154032 -0.01094254\n",
      " -0.03859154  0.03255036 -0.03629836 -0.00376652 -0.01963946 -0.0270079\n",
      " -0.03992144 -0.01768169 -0.02593839  0.08347559 -0.0424269  -0.0054187\n",
      "  0.00807384 -0.00737706 -0.04140578  0.05436123  0.02324943  0.03429426\n",
      " -0.02426596  0.04625561 -0.07233898 -0.05771087 -0.03379823  0.04426547\n",
      "  0.02406844  0.02483352  0.0382706   0.01990687  0.00062921  0.00992118\n",
      " -0.01834239  0.00608084  0.03877328 -0.04400546  0.00149051  0.02997329\n",
      "  0.01028026 -0.22375999  0.05698887  0.06806762  0.07706361  0.02253275\n",
      "  0.01913743  0.06551329 -0.06065976 -0.06323544 -0.01042216 -0.03753255\n",
      "  0.01151053  0.04453409 -0.02524224  0.00634898  0.01125808  0.1086152\n",
      " -0.0690057   0.02603765 -0.03969952 -0.04464141  0.05237647  0.14326562\n",
      "  0.05483185 -0.09159233  0.00864312  0.01686767  0.05582802  0.00050269\n",
      "  0.07304832  0.0430731  -0.04077491  0.07804794  0.04179394 -0.03200502\n",
      "  0.08833754 -0.01139688  0.04120976  0.01419881  0.06300842 -0.07655673\n",
      " -0.03577102 -0.03803146  0.03865914  0.05130146  0.02588633 -0.06477161\n",
      " -0.0254632  -0.04418924  0.01258217 -0.03123742 -0.04844946 -0.01392187\n",
      " -0.03720335  0.03491759  0.00400187 -0.02423381 -0.04944424 -0.09011127\n",
      "  0.02153505  0.0274417   0.00629192  0.04184948  0.05177146  0.04385964]\n",
      "Size of the embedding:  (384,)\n"
     ]
    }
   ],
   "source": [
    "huggingface_embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",  # alternatively use \"sentence-transformers/all-MiniLM-l6-v2\" for a light and faster experience.\n",
    "    model_kwargs={'device':'cpu'}, \n",
    "    encode_kwargs={'normalize_embeddings': True}\n",
    ")\n",
    "\n",
    "sample_embedding = np.array(huggingface_embeddings.embed_query(docs_after_split[0].page_content))\n",
    "print(\"Sample embedding of a document chunk: \", sample_embedding)\n",
    "print(\"Size of the embedding: \", sample_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieval System for vector embeddings\n",
    "#FAISS (Facebook AI Similarity Search) is a library that allows developers to quickly search for embeddings of multimedia documents that are similar to each other.\n",
    "\n",
    "vectorstore = FAISS.from_documents(docs_after_split, huggingface_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 documents retrieved which are relevant to the query. Display the first one:\n",
      "\n",
      "Vol. 3A 3-1CHAPTER 3\n",
      "PROTECTED-MODE MEMORY MANAGEMENT\n",
      "This chapter describes the Intel 64 and IA-32 architec ture’s protected-mode memory management facilities, \n",
      "including the physical memory requirements, se gmentation mechanism, and paging mechanism.\n",
      "See also: Chapter 5, “Protection‚” (for a description of  the processor’s protection mechanism) and Chapter 21, \n",
      "“8086 Emulation‚” (for a description of memory addressi ng protection in real-address and virtual-8086 modes).\n",
      "3.1 MEMORY MANAGEMENT OVERVIEW\n",
      "The memory management facilities of the IA-32 architectu re are divided into two parts: segmentation and paging.\n"
     ]
    }
   ],
   "source": [
    "query = \"Tell me something about computer architecrure\"\n",
    "relevant_documents = vectorstore.similarity_search(query)\n",
    "print(f'There are {len(relevant_documents)} documents retrieved which are relevant to the query. Display the first one:\\n')\n",
    "print(relevant_documents[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use similarity searching algorithm and return 3 most relevant documents.\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "\n",
    "#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\n",
    "\n",
    "hf = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-v0.1\",\n",
    "    model_kwargs={\"temperature\":0.1, \"max_length\":500})\n",
    "\n",
    "query = \"what is add instruction\" \n",
    "hf.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "give example of adding two values by storing in register and then adding them\n",
      "\n",
      "```\n",
      "\n",
      "mov r1, 10\n",
      "mov r2, 20\n",
      "add r1, r2\n",
      "```\n",
      "\n",
      "give example of adding two values by storing in register and then adding them\n",
      "\n",
      "```\n",
      "\n",
      "mov r1, 10\n",
      "mov r2, 20\n",
      "add r1, r2\n",
      "```\n",
      "\n",
      "give example of adding two values by storing in register and then\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.llms import HuggingFaceHub\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Obtain your API token and pass it explicitly\n",
    "api_token = \"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\"\n",
    "\n",
    "hf = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mistral-7B-v0.1\",\n",
    "    model_kwargs={\"temperature\": 0.1, \"max_length\": 500},\n",
    "    huggingfacehub_api_token=api_token  # Pass the token here\n",
    ")\n",
    "\n",
    "query = \"give example of adding two values by storing in register\"\n",
    "result = hf.invoke(query)\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
